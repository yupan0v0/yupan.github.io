---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

<!-- Yu Pan -->
I am currently a Ph.D. student in the Department of Information Science and Electrical Engineering at Kyushu University, working under the supervision of Prof. [Jianjun Zhao](https://stap.ait.kyushu-u.ac.jp/~zhao/index.html) and Prof. [Lei Ma](https://www.malei.org/). Prior to this, I received my Master's degree from Beijing Institute of Technology (BIT) and my Bachelor's degree from Northeastern University (NEU) in China.


My research interests primarily focus on the modeling of speech processing systems, including speech synthesis, voice conversion, speech recognition, speech emotion recognition. In addition, I am also interested in the Software Engineering (SE) support for complex AI-based systems (quality assurance for AI).


# üîç Research Area
**Speech Processing**: Speech Generation, Speech Recognition, Speech Emotion Generation

**Large Language Models**: Speech LLMs, Speech Tokenizer, Diffusion Models

**Software Engineering**: Software Testing, Analysis, and Repair


# üíª Internships
- *2022.12 - *, Everest Team - Ximalaya, China.


# üìù Publications 

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div> -->

2024:

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">IEEE SLT 2024</span> GMP-TL: Gender-augmented Multi-scale Pseudo-label Enhanced Transfer Learning for Speech Emotion Recognition. **Y Pan**, Y Yang, Y Huang, T Jin, J Yin, Y Hu, H Lu, L Ma, J Zhao. [[PDF]](https://arxiv.org/abs/2405.02151) 

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">ICASSP 2024</span> GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Accurate Speech Emotion Recognition. **Y Pan**, Y Hu, Y Yang, W Fei, J Yao, H Lu, L Ma, J Zhao. [[PDF]](https://arxiv.org/pdf/2306.07848) 

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">ICASSP 2024</span> PromptVC: Flexible stylistic voice conversion in latent space driven by natural language prompts. J Yao, Y Yang, Y Lei, Z Ning, Y Hu, **Y Pan**, J Yin, H Zhou, H Lu, L Xie. [[PDF]](https://arxiv.org/pdf/2309.09262)  [[DemoPage]](https://yaoxunji.github.io/prompt_vc/)

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">DCC 2024</span> Initialization Seeds Facilitating Neural Network Quantization. W Fei, L Ding, Y Pan, W Dai, C Li, J Zou, H Xiong. [[PDF]](https://ieeexplore.ieee.org/abstract/document/10533810)


2023:
- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">ICASSP 2023</span> Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism. Y Yang, **Y Pan**, J Yin, J Han, L Ma, H Lu. [[PDF]](https://ieeexplore.ieee.org/abstract/document/10096467)

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">SMAC 2023</span> Exploring the power of cross-contextual large language model in mimic emotion prediction. G Yi, Y Yang, **Y Pan**, Y Cao, J Yao, X Lv, C Fan, Z Lv, J Tao, S Liang, H Lu. [[PDF]](https://dl.acm.org/doi/10.1145/3606039.3613109) 


# üéñ Honors and Awards
- *2024.06* K2-SPRING Scholarship, Kyushu University, JAPAN. 
- *2023.10* The 1st place winner in the 4th Multimodal Sentiment Analysis Challenge (MuSe) Mimic Sub-challenge 2023 @ ACM MM Workshop. 
- *2022.06* Chinese Scholarship Council, CHINA. 
- *2020.12* Xiaomi Scholarship, BIT, CHINA. 
- *2020.10* Outstanding Graduate Student, BIT, CHINA.
- *2019.12* Huawei Scholarship, BIT, CHINA.
- *2018.06* Excellent Graduate, NEU, CHINA. 
- *2017.12* Outstanding Undergraduate Student, NEU, CHINA.
- *2017.12* Outstanding Undergraduate Student, NEU, CHINA.
- *2017.12* Caiguanshen Scholarship, NEU, CHINA.
- *2016.12* Outstanding Student Leader, NEU, CHINA.
- *2016.12* Caiguanshen Scholarship, NEU, CHINA.


Thanks for the template of [acad-homepage.github.io](https://github.com/RayeRen/acad-homepage.github.io)
